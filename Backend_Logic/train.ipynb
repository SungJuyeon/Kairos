{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 30, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'come',\n",
    "    'away',\n",
    "    'spin'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_come_1627646273.npy'),\n",
    "    np.load('dataset/seq_away_1627646273.npy'),\n",
    "    np.load('dataset/seq_spin_1627646273.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 30, 99)\n",
      "(1272,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 30, 99) (1144, 3)\n",
      "(128, 30, 99) (128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,163</span> (172.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,163\u001b[0m (172.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,163</span> (172.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,163\u001b[0m (172.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(30, 99)),  # 입력 형태에 맞게 수정\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6882 - loss: 0.8099 \n",
      "Epoch 1: val_acc improved from -inf to 0.99219, saving model to models/model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - acc: 0.7268 - loss: 0.7570 - val_acc: 0.9922 - val_loss: 0.1893 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9971 - loss: 0.1525\n",
      "Epoch 2: val_acc improved from 0.99219 to 1.00000, saving model to models/model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9972 - loss: 0.1454 - val_acc: 1.0000 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0166\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0158 - val_acc: 1.0000 - val_loss: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0038\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0037 - val_acc: 1.0000 - val_loss: 0.0021 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0020\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0020 - val_acc: 1.0000 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0014\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0014 - val_acc: 1.0000 - val_loss: 9.2178e-04 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.0635e-04\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.0168e-04 - val_acc: 1.0000 - val_loss: 6.2779e-04 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7257e-04\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.5858e-04 - val_acc: 1.0000 - val_loss: 4.5369e-04 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.4088e-04\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3479e-04 - val_acc: 1.0000 - val_loss: 3.1389e-04 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9386e-04\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9300e-04 - val_acc: 1.0000 - val_loss: 2.3955e-04 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4823e-04\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4366e-04 - val_acc: 1.0000 - val_loss: 1.9346e-04 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9609e-04\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9404e-04 - val_acc: 1.0000 - val_loss: 1.6167e-04 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6445e-04\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6280e-04 - val_acc: 1.0000 - val_loss: 1.3802e-04 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3746e-04\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3673e-04 - val_acc: 1.0000 - val_loss: 1.1935e-04 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2433e-04\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2306e-04 - val_acc: 1.0000 - val_loss: 1.0434e-04 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0969e-04\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0878e-04 - val_acc: 1.0000 - val_loss: 9.2213e-05 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.1797e-05\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.1991e-05 - val_acc: 1.0000 - val_loss: 8.2383e-05 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.3219e-05\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.3041e-05 - val_acc: 1.0000 - val_loss: 7.3935e-05 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.6827e-05\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6416e-05 - val_acc: 1.0000 - val_loss: 6.6851e-05 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.2560e-05\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1448e-05 - val_acc: 1.0000 - val_loss: 6.0718e-05 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0804e-05\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0825e-05 - val_acc: 1.0000 - val_loss: 5.5476e-05 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0367e-05\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.9537e-05 - val_acc: 1.0000 - val_loss: 5.0834e-05 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.3139e-05\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2892e-05 - val_acc: 1.0000 - val_loss: 4.6808e-05 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.1572e-05\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0630e-05 - val_acc: 1.0000 - val_loss: 4.3218e-05 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.6890e-05\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6500e-05 - val_acc: 1.0000 - val_loss: 4.0022e-05 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2169e-05\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.1978e-05 - val_acc: 1.0000 - val_loss: 3.7222e-05 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.8834e-05\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8759e-05 - val_acc: 1.0000 - val_loss: 3.4672e-05 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5864e-05\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5880e-05 - val_acc: 1.0000 - val_loss: 3.2365e-05 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5330e-05\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4968e-05 - val_acc: 1.0000 - val_loss: 3.0282e-05 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0039e-05\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0305e-05 - val_acc: 1.0000 - val_loss: 2.8422e-05 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9942e-05\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9842e-05 - val_acc: 1.0000 - val_loss: 2.6697e-05 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7435e-05\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7482e-05 - val_acc: 1.0000 - val_loss: 2.5127e-05 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7247e-05\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7032e-05 - val_acc: 1.0000 - val_loss: 2.3682e-05 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4476e-05\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4513e-05 - val_acc: 1.0000 - val_loss: 2.2381e-05 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3970e-05\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3876e-05 - val_acc: 1.0000 - val_loss: 2.1162e-05 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3637e-05\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3398e-05 - val_acc: 1.0000 - val_loss: 2.0048e-05 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1247e-05\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1184e-05 - val_acc: 1.0000 - val_loss: 1.9013e-05 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9848e-05\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9849e-05 - val_acc: 1.0000 - val_loss: 1.8058e-05 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9039e-05\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9013e-05 - val_acc: 1.0000 - val_loss: 1.7171e-05 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7961e-05\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7972e-05 - val_acc: 1.0000 - val_loss: 1.6348e-05 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6956e-05\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6982e-05 - val_acc: 1.0000 - val_loss: 1.5574e-05 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6301e-05\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6304e-05 - val_acc: 1.0000 - val_loss: 1.4849e-05 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5947e-05\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5902e-05 - val_acc: 1.0000 - val_loss: 1.4180e-05 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4970e-05\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.4963e-05 - val_acc: 1.0000 - val_loss: 1.3549e-05 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4520e-05\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4474e-05 - val_acc: 1.0000 - val_loss: 1.2951e-05 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4111e-05\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4018e-05 - val_acc: 1.0000 - val_loss: 1.2408e-05 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3285e-05\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.3279e-05 - val_acc: 1.0000 - val_loss: 1.1882e-05 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2903e-05\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2832e-05 - val_acc: 1.0000 - val_loss: 1.1389e-05 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1924e-05\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1965e-05 - val_acc: 1.0000 - val_loss: 1.0924e-05 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1462e-05\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1464e-05 - val_acc: 1.0000 - val_loss: 1.0488e-05 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0874e-05\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0920e-05 - val_acc: 1.0000 - val_loss: 1.0076e-05 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1017e-05\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0941e-05 - val_acc: 1.0000 - val_loss: 9.6820e-06 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0568e-05\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0522e-05 - val_acc: 1.0000 - val_loss: 9.4985e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0011e-05\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0041e-05 - val_acc: 1.0000 - val_loss: 9.3057e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0043e-05\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0034e-05 - val_acc: 1.0000 - val_loss: 9.1306e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7852e-06\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7718e-06 - val_acc: 1.0000 - val_loss: 8.9490e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.6607e-06\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.6577e-06 - val_acc: 1.0000 - val_loss: 8.7749e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.1617e-06\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.2098e-06 - val_acc: 1.0000 - val_loss: 8.6082e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.5236e-06\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.4705e-06 - val_acc: 1.0000 - val_loss: 8.4387e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.6924e-06\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.7478e-06 - val_acc: 1.0000 - val_loss: 8.2701e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.2057e-06\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.1368e-06 - val_acc: 1.0000 - val_loss: 8.1090e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.7539e-06\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.7344e-06 - val_acc: 1.0000 - val_loss: 7.9544e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.2520e-06\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.2792e-06 - val_acc: 1.0000 - val_loss: 7.7914e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1493e-06\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1859e-06 - val_acc: 1.0000 - val_loss: 7.6396e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.3315e-06\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.2974e-06 - val_acc: 1.0000 - val_loss: 7.4859e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.1445e-06\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1173e-06 - val_acc: 1.0000 - val_loss: 7.3425e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.9529e-06\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.9370e-06 - val_acc: 1.0000 - val_loss: 7.1963e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.6455e-06\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6592e-06 - val_acc: 1.0000 - val_loss: 7.0501e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6136e-06\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5993e-06 - val_acc: 1.0000 - val_loss: 6.9104e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.5438e-06\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5143e-06 - val_acc: 1.0000 - val_loss: 6.7670e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.0740e-06\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.0989e-06 - val_acc: 1.0000 - val_loss: 6.6394e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1738e-06\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1677e-06 - val_acc: 1.0000 - val_loss: 6.5025e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.0055e-06\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.0042e-06 - val_acc: 1.0000 - val_loss: 6.3721e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.9830e-06\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.9586e-06 - val_acc: 1.0000 - val_loss: 6.2445e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7009e-06\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.6975e-06 - val_acc: 1.0000 - val_loss: 6.1271e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.8468e-06\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7971e-06 - val_acc: 1.0000 - val_loss: 5.9940e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7661e-06\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.6973e-06 - val_acc: 1.0000 - val_loss: 5.8794e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.3514e-06\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.3447e-06 - val_acc: 1.0000 - val_loss: 5.7565e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1791e-06\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1749e-06 - val_acc: 1.0000 - val_loss: 5.6503e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0998e-06\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0926e-06 - val_acc: 1.0000 - val_loss: 5.5339e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.8154e-06\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.8421e-06 - val_acc: 1.0000 - val_loss: 5.4249e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.7498e-06\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.7606e-06 - val_acc: 1.0000 - val_loss: 5.3150e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.7801e-06\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.7730e-06 - val_acc: 1.0000 - val_loss: 5.2089e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.7170e-06\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.6823e-06 - val_acc: 1.0000 - val_loss: 5.1046e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3364e-06\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3642e-06 - val_acc: 1.0000 - val_loss: 5.0040e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4389e-06\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4190e-06 - val_acc: 1.0000 - val_loss: 4.9034e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.1832e-06\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.1962e-06 - val_acc: 1.0000 - val_loss: 4.8009e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.1548e-06\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.1546e-06 - val_acc: 1.0000 - val_loss: 4.7115e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.0426e-06\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0446e-06 - val_acc: 1.0000 - val_loss: 4.6156e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0326e-06\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0199e-06 - val_acc: 1.0000 - val_loss: 4.5094e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0252e-06\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.9925e-06 - val_acc: 1.0000 - val_loss: 4.4256e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6893e-06\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.6908e-06 - val_acc: 1.0000 - val_loss: 4.3502e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.9371e-06\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8870e-06 - val_acc: 1.0000 - val_loss: 4.2505e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6984e-06\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6741e-06 - val_acc: 1.0000 - val_loss: 4.1751e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5862e-06\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5693e-06 - val_acc: 1.0000 - val_loss: 4.0838e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.4646e-06\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4529e-06 - val_acc: 1.0000 - val_loss: 3.9991e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4449e-06\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4158e-06 - val_acc: 1.0000 - val_loss: 3.9320e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3412e-06\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3075e-06 - val_acc: 1.0000 - val_loss: 3.8464e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2538e-06\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2310e-06 - val_acc: 1.0000 - val_loss: 3.7737e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.0527e-06\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.0493e-06 - val_acc: 1.0000 - val_loss: 3.6899e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9710e-06\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9689e-06 - val_acc: 1.0000 - val_loss: 3.6256e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9296e-06\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9255e-06 - val_acc: 1.0000 - val_loss: 3.5455e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9579e-06\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9299e-06 - val_acc: 1.0000 - val_loss: 3.5074e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6306e-06\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6609e-06 - val_acc: 1.0000 - val_loss: 3.4785e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7972e-06\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7882e-06 - val_acc: 1.0000 - val_loss: 3.4422e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6378e-06\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6515e-06 - val_acc: 1.0000 - val_loss: 3.4105e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8063e-06\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7784e-06 - val_acc: 1.0000 - val_loss: 3.3779e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7527e-06\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7236e-06 - val_acc: 1.0000 - val_loss: 3.3351e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7419e-06\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7108e-06 - val_acc: 1.0000 - val_loss: 3.2969e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6456e-06\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6289e-06 - val_acc: 1.0000 - val_loss: 3.2671e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5159e-06\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5123e-06 - val_acc: 1.0000 - val_loss: 3.2289e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.4177e-06\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4301e-06 - val_acc: 1.0000 - val_loss: 3.1916e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5241e-06\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5103e-06 - val_acc: 1.0000 - val_loss: 3.1572e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4447e-06\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4386e-06 - val_acc: 1.0000 - val_loss: 3.1246e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3229e-06\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3295e-06 - val_acc: 1.0000 - val_loss: 3.0938e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3473e-06\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3468e-06 - val_acc: 1.0000 - val_loss: 3.0612e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.3626e-06\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3499e-06 - val_acc: 1.0000 - val_loss: 3.0314e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.0908e-06\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1190e-06 - val_acc: 1.0000 - val_loss: 2.9886e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1191e-06\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1393e-06 - val_acc: 1.0000 - val_loss: 2.9514e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1435e-06\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1496e-06 - val_acc: 1.0000 - val_loss: 2.9169e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.1225e-06\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1280e-06 - val_acc: 1.0000 - val_loss: 2.8880e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1354e-06\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1299e-06 - val_acc: 1.0000 - val_loss: 2.8536e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.0938e-06\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 3.0925e-06 - val_acc: 1.0000 - val_loss: 2.8154e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1098e-06\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0935e-06 - val_acc: 1.0000 - val_loss: 2.7856e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0014e-06\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.0014e-06 - val_acc: 1.0000 - val_loss: 2.7539e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0674e-06\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0486e-06 - val_acc: 1.0000 - val_loss: 2.7195e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9275e-06\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9294e-06 - val_acc: 1.0000 - val_loss: 2.6906e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7956e-06\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8162e-06 - val_acc: 1.0000 - val_loss: 2.6515e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9846e-06\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9504e-06 - val_acc: 1.0000 - val_loss: 2.6217e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9858e-06\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9521e-06 - val_acc: 1.0000 - val_loss: 2.5937e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8223e-06\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8170e-06 - val_acc: 1.0000 - val_loss: 2.5686e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7605e-06\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7602e-06 - val_acc: 1.0000 - val_loss: 2.5267e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7424e-06\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7375e-06 - val_acc: 1.0000 - val_loss: 2.4959e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8259e-06\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7985e-06 - val_acc: 1.0000 - val_loss: 2.4605e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6099e-06\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.6120e-06 - val_acc: 1.0000 - val_loss: 2.4363e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5321e-06\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5466e-06 - val_acc: 1.0000 - val_loss: 2.4037e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5007e-06\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5094e-06 - val_acc: 1.0000 - val_loss: 2.3618e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7067e-06\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6773e-06 - val_acc: 1.0000 - val_loss: 2.3292e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5332e-06\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5291e-06 - val_acc: 1.0000 - val_loss: 2.3004e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4441e-06\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4550e-06 - val_acc: 1.0000 - val_loss: 2.2799e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4680e-06\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4649e-06 - val_acc: 1.0000 - val_loss: 2.2594e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3537e-06\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3575e-06 - val_acc: 1.0000 - val_loss: 2.2212e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4618e-06\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4450e-06 - val_acc: 1.0000 - val_loss: 2.1895e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3066e-06\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3176e-06 - val_acc: 1.0000 - val_loss: 2.1644e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3350e-06\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3325e-06 - val_acc: 1.0000 - val_loss: 2.1337e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.2817e-06\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2815e-06 - val_acc: 1.0000 - val_loss: 2.1057e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3177e-06\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3093e-06 - val_acc: 1.0000 - val_loss: 2.0731e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2437e-06\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2407e-06 - val_acc: 1.0000 - val_loss: 2.0396e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3008e-06\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2832e-06 - val_acc: 1.0000 - val_loss: 2.0135e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2015e-06\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1958e-06 - val_acc: 1.0000 - val_loss: 1.9902e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1569e-06\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1552e-06 - val_acc: 1.0000 - val_loss: 1.9614e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0922e-06\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0970e-06 - val_acc: 1.0000 - val_loss: 1.9344e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0411e-06\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.0471e-06 - val_acc: 1.0000 - val_loss: 1.9204e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.0546e-06\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0595e-06 - val_acc: 1.0000 - val_loss: 1.9064e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0041e-06\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0131e-06 - val_acc: 1.0000 - val_loss: 1.8934e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0949e-06\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0860e-06 - val_acc: 1.0000 - val_loss: 1.8766e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9701e-06\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9829e-06 - val_acc: 1.0000 - val_loss: 1.8673e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0328e-06\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0298e-06 - val_acc: 1.0000 - val_loss: 1.8496e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1046e-06\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.0794e-06 - val_acc: 1.0000 - val_loss: 1.8431e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9402e-06\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9511e-06 - val_acc: 1.0000 - val_loss: 1.8245e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9880e-06\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9848e-06 - val_acc: 1.0000 - val_loss: 1.8105e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9349e-06\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9354e-06 - val_acc: 1.0000 - val_loss: 1.7947e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9512e-06\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9487e-06 - val_acc: 1.0000 - val_loss: 1.7844e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9441e-06\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9431e-06 - val_acc: 1.0000 - val_loss: 1.7723e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9463e-06\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9454e-06 - val_acc: 1.0000 - val_loss: 1.7555e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8700e-06\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8771e-06 - val_acc: 1.0000 - val_loss: 1.7444e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9398e-06\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9284e-06 - val_acc: 1.0000 - val_loss: 1.7313e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8945e-06\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8892e-06 - val_acc: 1.0000 - val_loss: 1.7183e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8780e-06\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8766e-06 - val_acc: 1.0000 - val_loss: 1.7052e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8140e-06\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.8152e-06 - val_acc: 1.0000 - val_loss: 1.6913e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8285e-06\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8251e-06 - val_acc: 1.0000 - val_loss: 1.6745e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7881e-06\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7944e-06 - val_acc: 1.0000 - val_loss: 1.6559e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7222e-06\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7322e-06 - val_acc: 1.0000 - val_loss: 1.6391e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7352e-06\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7428e-06 - val_acc: 1.0000 - val_loss: 1.6252e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7956e-06\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7944e-06 - val_acc: 1.0000 - val_loss: 1.6112e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7955e-06\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7832e-06 - val_acc: 1.0000 - val_loss: 1.5916e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7023e-06\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7059e-06 - val_acc: 1.0000 - val_loss: 1.5814e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7226e-06\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7221e-06 - val_acc: 1.0000 - val_loss: 1.5693e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7175e-06\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7140e-06 - val_acc: 1.0000 - val_loss: 1.5590e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7091e-06\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7068e-06 - val_acc: 1.0000 - val_loss: 1.5395e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6852e-06\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6814e-06 - val_acc: 1.0000 - val_loss: 1.5218e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6474e-06\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6461e-06 - val_acc: 1.0000 - val_loss: 1.4994e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6664e-06\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6611e-06 - val_acc: 1.0000 - val_loss: 1.4920e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6398e-06\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6391e-06 - val_acc: 1.0000 - val_loss: 1.4808e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6629e-06\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6564e-06 - val_acc: 1.0000 - val_loss: 1.4678e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6019e-06\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6004e-06 - val_acc: 1.0000 - val_loss: 1.4566e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5206e-06\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5362e-06 - val_acc: 1.0000 - val_loss: 1.4482e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5122e-06\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5233e-06 - val_acc: 1.0000 - val_loss: 1.4361e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5288e-06\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5328e-06 - val_acc: 1.0000 - val_loss: 1.4203e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5489e-06\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.5479e-06 - val_acc: 1.0000 - val_loss: 1.4026e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5369e-06\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5324e-06 - val_acc: 1.0000 - val_loss: 1.3821e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4285e-06\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4390e-06 - val_acc: 1.0000 - val_loss: 1.3672e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4740e-06\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4750e-06 - val_acc: 1.0000 - val_loss: 1.3579e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4881e-06\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.4874e-06 - val_acc: 1.0000 - val_loss: 1.3420e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5082e-06\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4974e-06 - val_acc: 1.0000 - val_loss: 1.3281e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4967e-06\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4854e-06 - val_acc: 1.0000 - val_loss: 1.3169e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4230e-06\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4238e-06 - val_acc: 1.0000 - val_loss: 1.3094e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4024e-06\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4045e-06 - val_acc: 1.0000 - val_loss: 1.2955e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4489e-06\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4380e-06 - val_acc: 1.0000 - val_loss: 1.2824e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4243e-06\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4165e-06 - val_acc: 1.0000 - val_loss: 1.2610e-06 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# 모델 학습 및 저장\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.keras', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),  # 확장자 변경\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")\n",
    "# 모델 저장\n",
    "model.save('models/model.keras')  # 확장자 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[94,  0],\n",
       "        [ 0, 34]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 47]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 47]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.keras')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
