{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 30, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'come',\n",
    "    'away',\n",
    "    'spin'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_come_1627646273.npy'),\n",
    "    np.load('dataset/seq_away_1627646273.npy'),\n",
    "    np.load('dataset/seq_spin_1627646273.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 30, 99)\n",
      "(1272,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 30, 99) (1144, 3)\n",
      "(128, 30, 99) (128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,163</span> (172.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,163\u001b[0m (172.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,163</span> (172.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,163\u001b[0m (172.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=x_train.shape[1:3]),  # 활성화 함수 변경\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.7209 - loss: 0.8031 \n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to models/model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - acc: 0.7669 - loss: 0.7305 - val_acc: 1.0000 - val_loss: 0.1278 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0886\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0854 - val_acc: 1.0000 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0181\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0174 - val_acc: 1.0000 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0083\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0079 - val_acc: 1.0000 - val_loss: 0.0049 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0044\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0043 - val_acc: 1.0000 - val_loss: 0.0031 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0027\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0027 - val_acc: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0020\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0020 - val_acc: 1.0000 - val_loss: 0.0016 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0015\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 0.0015 - val_acc: 1.0000 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0012\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0012 - val_acc: 1.0000 - val_loss: 9.9967e-04 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0010\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0010 - val_acc: 1.0000 - val_loss: 8.1257e-04 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6876e-04\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.6825e-04 - val_acc: 1.0000 - val_loss: 6.8899e-04 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.3623e-04\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.3632e-04 - val_acc: 1.0000 - val_loss: 5.7848e-04 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2629e-04\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.2777e-04 - val_acc: 1.0000 - val_loss: 4.9668e-04 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0872e-04\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.0093e-04 - val_acc: 1.0000 - val_loss: 4.2909e-04 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.3272e-04\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.2916e-04 - val_acc: 1.0000 - val_loss: 3.7608e-04 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.5920e-04\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.5944e-04 - val_acc: 1.0000 - val_loss: 3.3218e-04 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.2148e-04\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.2138e-04 - val_acc: 1.0000 - val_loss: 2.9491e-04 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.7820e-04\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.7836e-04 - val_acc: 1.0000 - val_loss: 2.6386e-04 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 2.5168e-04\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 2.5184e-04 - val_acc: 1.0000 - val_loss: 2.3643e-04 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.2666e-04\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.2672e-04 - val_acc: 1.0000 - val_loss: 2.1205e-04 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.0250e-04\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.0305e-04 - val_acc: 1.0000 - val_loss: 1.9017e-04 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9016e-04\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.8998e-04 - val_acc: 1.0000 - val_loss: 1.6885e-04 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7426e-04\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7331e-04 - val_acc: 1.0000 - val_loss: 1.5055e-04 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.4660e-04\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4852e-04 - val_acc: 1.0000 - val_loss: 1.7711e-04 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.4448e-04\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.4370e-04 - val_acc: 1.0000 - val_loss: 1.1609e-04 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.1862e-04\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.1856e-04 - val_acc: 1.0000 - val_loss: 1.0158e-04 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0958e-04\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0881e-04 - val_acc: 1.0000 - val_loss: 9.3162e-05 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0557e-04\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0379e-04 - val_acc: 1.0000 - val_loss: 8.6600e-05 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.2730e-05\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.2640e-05 - val_acc: 1.0000 - val_loss: 8.0822e-05 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.6862e-05\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.6818e-05 - val_acc: 1.0000 - val_loss: 7.5905e-05 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.6416e-05\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.5917e-05 - val_acc: 1.0000 - val_loss: 7.1374e-05 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0248e-05\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.9266e-05 - val_acc: 1.0000 - val_loss: 6.7303e-05 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.0599e-05\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.0652e-05 - val_acc: 1.0000 - val_loss: 6.3583e-05 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.0020e-05\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.9677e-05 - val_acc: 1.0000 - val_loss: 6.0105e-05 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 6.3692e-05\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 6.3687e-05 - val_acc: 1.0000 - val_loss: 5.7003e-05 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 6.0444e-05\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 6.0436e-05 - val_acc: 1.0000 - val_loss: 5.3966e-05 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 5.7839e-05\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 1.0000 - loss: 5.7765e-05 - val_acc: 1.0000 - val_loss: 5.1274e-05 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 1.0000 - loss: 5.6462e-05\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 1.0000 - loss: 5.6197e-05 - val_acc: 1.0000 - val_loss: 4.8684e-05 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 1.0000 - loss: 4.9181e-05\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 1.0000 - loss: 4.9311e-05 - val_acc: 1.0000 - val_loss: 4.6368e-05 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 4.9334e-05\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - acc: 1.0000 - loss: 4.9287e-05 - val_acc: 1.0000 - val_loss: 4.4184e-05 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 4.5825e-05\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 1.0000 - loss: 4.5852e-05 - val_acc: 1.0000 - val_loss: 4.2096e-05 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 1.0000 - loss: 4.6856e-05\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - acc: 1.0000 - loss: 4.6797e-05 - val_acc: 1.0000 - val_loss: 4.0176e-05 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 1.0000 - loss: 4.6849e-05\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - acc: 1.0000 - loss: 4.6734e-05 - val_acc: 1.0000 - val_loss: 3.8370e-05 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 1.0000 - loss: 4.4516e-05\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - acc: 1.0000 - loss: 4.4310e-05 - val_acc: 1.0000 - val_loss: 3.6672e-05 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 1.0000 - loss: 3.9686e-05\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 1.0000 - loss: 3.9628e-05 - val_acc: 1.0000 - val_loss: 3.5087e-05 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 1.0000 - loss: 3.9524e-05\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 1.0000 - loss: 3.9341e-05 - val_acc: 1.0000 - val_loss: 3.3581e-05 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 1.0000 - loss: 3.5126e-05\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - acc: 1.0000 - loss: 3.5170e-05 - val_acc: 1.0000 - val_loss: 3.2203e-05 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 1.0000 - loss: 3.4448e-05\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 1.0000 - loss: 3.4430e-05 - val_acc: 1.0000 - val_loss: 3.0850e-05 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 1.0000 - loss: 3.1128e-05\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - acc: 1.0000 - loss: 3.1215e-05 - val_acc: 1.0000 - val_loss: 2.9620e-05 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 1.0000 - loss: 3.3776e-05\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - acc: 1.0000 - loss: 3.3650e-05 - val_acc: 1.0000 - val_loss: 2.8408e-05 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 1.0000 - loss: 3.1183e-05\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 1.0000 - loss: 3.1038e-05 - val_acc: 1.0000 - val_loss: 2.7305e-05 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.8649e-05\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 2.8764e-05 - val_acc: 1.0000 - val_loss: 2.6778e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.8630e-05\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.8664e-05 - val_acc: 1.0000 - val_loss: 2.6236e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.7926e-05\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.7941e-05 - val_acc: 1.0000 - val_loss: 2.5724e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.7892e-05\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.7849e-05 - val_acc: 1.0000 - val_loss: 2.5197e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.7853e-05\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.7829e-05 - val_acc: 1.0000 - val_loss: 2.4701e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.0524e-05\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.9631e-05 - val_acc: 1.0000 - val_loss: 2.4207e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5073e-05\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.5140e-05 - val_acc: 1.0000 - val_loss: 2.3714e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.6512e-05\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.6360e-05 - val_acc: 1.0000 - val_loss: 2.3245e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.6661e-05\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.6255e-05 - val_acc: 1.0000 - val_loss: 2.2777e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4302e-05\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.4305e-05 - val_acc: 1.0000 - val_loss: 2.2318e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3391e-05\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3425e-05 - val_acc: 1.0000 - val_loss: 2.1870e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3264e-05\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3275e-05 - val_acc: 1.0000 - val_loss: 2.1426e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.2803e-05\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.2807e-05 - val_acc: 1.0000 - val_loss: 2.0985e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2883e-05\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.2848e-05 - val_acc: 1.0000 - val_loss: 2.0575e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3824e-05\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3724e-05 - val_acc: 1.0000 - val_loss: 2.0141e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1747e-05\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1677e-05 - val_acc: 1.0000 - val_loss: 1.9734e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0807e-05\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0882e-05 - val_acc: 1.0000 - val_loss: 1.9335e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0252e-05\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0329e-05 - val_acc: 1.0000 - val_loss: 1.8940e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0100e-05\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0102e-05 - val_acc: 1.0000 - val_loss: 1.8556e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9452e-05\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9543e-05 - val_acc: 1.0000 - val_loss: 1.8172e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8184e-05\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8436e-05 - val_acc: 1.0000 - val_loss: 1.7808e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8748e-05\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8760e-05 - val_acc: 1.0000 - val_loss: 1.7441e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8376e-05\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8435e-05 - val_acc: 1.0000 - val_loss: 1.7087e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7538e-05\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7666e-05 - val_acc: 1.0000 - val_loss: 1.6732e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7288e-05\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7411e-05 - val_acc: 1.0000 - val_loss: 1.6384e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7550e-05\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7530e-05 - val_acc: 1.0000 - val_loss: 1.6055e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6851e-05\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6862e-05 - val_acc: 1.0000 - val_loss: 1.5713e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6429e-05\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6532e-05 - val_acc: 1.0000 - val_loss: 1.5402e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7524e-05\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7289e-05 - val_acc: 1.0000 - val_loss: 1.5078e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6043e-05\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6067e-05 - val_acc: 1.0000 - val_loss: 1.4773e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5466e-05\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5527e-05 - val_acc: 1.0000 - val_loss: 1.4470e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4959e-05\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5033e-05 - val_acc: 1.0000 - val_loss: 1.4165e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5109e-05\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5091e-05 - val_acc: 1.0000 - val_loss: 1.3869e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4552e-05\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.4570e-05 - val_acc: 1.0000 - val_loss: 1.3591e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4978e-05\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4855e-05 - val_acc: 1.0000 - val_loss: 1.3303e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3903e-05\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3949e-05 - val_acc: 1.0000 - val_loss: 1.3037e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4241e-05\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4189e-05 - val_acc: 1.0000 - val_loss: 1.2761e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3261e-05\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3318e-05 - val_acc: 1.0000 - val_loss: 1.2509e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4238e-05\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4031e-05 - val_acc: 1.0000 - val_loss: 1.2247e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2736e-05\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2833e-05 - val_acc: 1.0000 - val_loss: 1.1984e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3748e-05\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3498e-05 - val_acc: 1.0000 - val_loss: 1.1742e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3589e-05\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3348e-05 - val_acc: 1.0000 - val_loss: 1.1501e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.1697e-05 \n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 1.1738e-05 - val_acc: 1.0000 - val_loss: 1.1262e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1543e-05\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1594e-05 - val_acc: 1.0000 - val_loss: 1.1035e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2020e-05\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1953e-05 - val_acc: 1.0000 - val_loss: 1.0796e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1259e-05\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1270e-05 - val_acc: 1.0000 - val_loss: 1.0575e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1191e-05\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1202e-05 - val_acc: 1.0000 - val_loss: 1.0363e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1852e-05\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1682e-05 - val_acc: 1.0000 - val_loss: 1.0136e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0747e-05\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0771e-05 - val_acc: 1.0000 - val_loss: 9.9334e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0126e-05\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0173e-05 - val_acc: 1.0000 - val_loss: 9.7295e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0033e-05\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0051e-05 - val_acc: 1.0000 - val_loss: 9.6242e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.6614e-06\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7801e-06 - val_acc: 1.0000 - val_loss: 9.5208e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0590e-05\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0578e-05 - val_acc: 1.0000 - val_loss: 9.4147e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.5027e-06\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 9.5467e-06 - val_acc: 1.0000 - val_loss: 9.3262e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.9579e-06\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.9653e-06 - val_acc: 1.0000 - val_loss: 9.2191e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.9656e-06\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.9553e-06 - val_acc: 1.0000 - val_loss: 9.1139e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0268e-05\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0155e-05 - val_acc: 1.0000 - val_loss: 9.0133e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.4656e-06\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.4733e-06 - val_acc: 1.0000 - val_loss: 8.9192e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7141e-06\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.6910e-06 - val_acc: 1.0000 - val_loss: 8.8140e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.2831e-06\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.2890e-06 - val_acc: 1.0000 - val_loss: 8.7125e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.0818e-06\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.1561e-06 - val_acc: 1.0000 - val_loss: 8.6184e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.6134e-06\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.5486e-06 - val_acc: 1.0000 - val_loss: 8.5169e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.2216e-06\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.2139e-06 - val_acc: 1.0000 - val_loss: 8.4163e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.7885e-06\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.8275e-06 - val_acc: 1.0000 - val_loss: 8.3157e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.4668e-06\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.5357e-06 - val_acc: 1.0000 - val_loss: 8.2142e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.4706e-06\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.3200e-06 - val_acc: 1.0000 - val_loss: 8.1313e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.5192e-06\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.5494e-06 - val_acc: 1.0000 - val_loss: 8.0289e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.2015e-06\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.2612e-06 - val_acc: 1.0000 - val_loss: 7.9274e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.5575e-06\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.5330e-06 - val_acc: 1.0000 - val_loss: 7.8361e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.9926e-06\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0538e-06 - val_acc: 1.0000 - val_loss: 7.7346e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1614e-06\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1563e-06 - val_acc: 1.0000 - val_loss: 7.6377e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.4517e-06\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.3666e-06 - val_acc: 1.0000 - val_loss: 7.5465e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.9741e-06\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0033e-06 - val_acc: 1.0000 - val_loss: 7.4571e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5876e-06\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6570e-06 - val_acc: 1.0000 - val_loss: 7.3518e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6705e-06\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7127e-06 - val_acc: 1.0000 - val_loss: 7.2512e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.1956e-06\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1199e-06 - val_acc: 1.0000 - val_loss: 7.1711e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5798e-06\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6016e-06 - val_acc: 1.0000 - val_loss: 7.0752e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0278e-06\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.9176e-06 - val_acc: 1.0000 - val_loss: 6.9728e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6986e-06\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.6764e-06 - val_acc: 1.0000 - val_loss: 6.8815e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1882e-06\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.2128e-06 - val_acc: 1.0000 - val_loss: 6.7902e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5244e-06\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.4566e-06 - val_acc: 1.0000 - val_loss: 6.6952e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.9287e-06\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.9338e-06 - val_acc: 1.0000 - val_loss: 6.5891e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.6952e-06\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7332e-06 - val_acc: 1.0000 - val_loss: 6.4559e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.8740e-06\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.8705e-06 - val_acc: 1.0000 - val_loss: 6.3041e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7726e-06\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7525e-06 - val_acc: 1.0000 - val_loss: 6.1327e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.5055e-06\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.5016e-06 - val_acc: 1.0000 - val_loss: 5.7844e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1453e-06\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.1432e-06 - val_acc: 1.0000 - val_loss: 5.6401e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.1165e-06\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0591e-06 - val_acc: 1.0000 - val_loss: 5.4966e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.5047e-06\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.5441e-06 - val_acc: 1.0000 - val_loss: 5.3895e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.0118e-06\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.9515e-06 - val_acc: 1.0000 - val_loss: 5.3039e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.9212e-06\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.8633e-06 - val_acc: 1.0000 - val_loss: 5.2191e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3319e-06\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.3459e-06 - val_acc: 1.0000 - val_loss: 5.1455e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.8403e-06\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.7743e-06 - val_acc: 1.0000 - val_loss: 5.0599e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.9219e-06\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0373e-06 - val_acc: 1.0000 - val_loss: 4.9900e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.5010e-06\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4628e-06 - val_acc: 1.0000 - val_loss: 4.9174e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0904e-06\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.1162e-06 - val_acc: 1.0000 - val_loss: 4.8438e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0218e-06\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0508e-06 - val_acc: 1.0000 - val_loss: 4.7749e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0268e-06\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.0279e-06 - val_acc: 1.0000 - val_loss: 4.7078e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.9662e-06\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.9745e-06 - val_acc: 1.0000 - val_loss: 4.6249e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.1002e-06\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0690e-06 - val_acc: 1.0000 - val_loss: 4.5551e-06 - learning_rate: 2.5000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.8521e-06\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8554e-06 - val_acc: 1.0000 - val_loss: 4.5290e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8408e-06\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.8343e-06 - val_acc: 1.0000 - val_loss: 4.4824e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7174e-06\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7334e-06 - val_acc: 1.0000 - val_loss: 4.4424e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5391e-06\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.5440e-06 - val_acc: 1.0000 - val_loss: 4.4033e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.6048e-06\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6109e-06 - val_acc: 1.0000 - val_loss: 4.3614e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5356e-06\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5408e-06 - val_acc: 1.0000 - val_loss: 4.3195e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.6604e-06\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6367e-06 - val_acc: 1.0000 - val_loss: 4.2757e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7484e-06\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7133e-06 - val_acc: 1.0000 - val_loss: 4.2356e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4118e-06\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.4204e-06 - val_acc: 1.0000 - val_loss: 4.1900e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2751e-06\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3161e-06 - val_acc: 1.0000 - val_loss: 4.1537e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3587e-06\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3741e-06 - val_acc: 1.0000 - val_loss: 4.1202e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2668e-06\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2912e-06 - val_acc: 1.0000 - val_loss: 4.0792e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3343e-06\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3410e-06 - val_acc: 1.0000 - val_loss: 4.0419e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7228e-06\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.7117e-06 - val_acc: 1.0000 - val_loss: 4.0000e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3320e-06\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.3271e-06 - val_acc: 1.0000 - val_loss: 3.9665e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3642e-06\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3388e-06 - val_acc: 1.0000 - val_loss: 3.9237e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.0392e-06\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.0617e-06 - val_acc: 1.0000 - val_loss: 3.8892e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2170e-06\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2090e-06 - val_acc: 1.0000 - val_loss: 3.8389e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.1255e-06\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.1256e-06 - val_acc: 1.0000 - val_loss: 3.7886e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.3666e-06\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3100e-06 - val_acc: 1.0000 - val_loss: 3.7504e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.1192e-06\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.0989e-06 - val_acc: 1.0000 - val_loss: 3.7076e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.8760e-06\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8905e-06 - val_acc: 1.0000 - val_loss: 3.6517e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.9201e-06 \n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.9240e-06 - val_acc: 1.0000 - val_loss: 3.6070e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8061e-06\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.8079e-06 - val_acc: 1.0000 - val_loss: 3.5511e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9599e-06\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.9489e-06 - val_acc: 1.0000 - val_loss: 3.4999e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.7188e-06\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7261e-06 - val_acc: 1.0000 - val_loss: 3.4431e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8574e-06\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.8494e-06 - val_acc: 1.0000 - val_loss: 3.3826e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.0038e-06\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9389e-06 - val_acc: 1.0000 - val_loss: 3.3230e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5640e-06\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5746e-06 - val_acc: 1.0000 - val_loss: 3.2848e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5461e-06\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5414e-06 - val_acc: 1.0000 - val_loss: 3.2214e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.4009e-06\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.4142e-06 - val_acc: 1.0000 - val_loss: 3.1739e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4607e-06\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4563e-06 - val_acc: 1.0000 - val_loss: 3.1153e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6631e-06\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.5945e-06 - val_acc: 1.0000 - val_loss: 3.0631e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.6106e-06\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5570e-06 - val_acc: 1.0000 - val_loss: 3.0063e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.2092e-06\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.2107e-06 - val_acc: 1.0000 - val_loss: 2.9691e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9904e-06\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.0026e-06 - val_acc: 1.0000 - val_loss: 2.9318e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1417e-06\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1486e-06 - val_acc: 1.0000 - val_loss: 2.8713e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0519e-06\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0683e-06 - val_acc: 1.0000 - val_loss: 2.8238e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8909e-06\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9149e-06 - val_acc: 1.0000 - val_loss: 2.7912e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0642e-06\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.0629e-06 - val_acc: 1.0000 - val_loss: 2.7409e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.0174e-06\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.0083e-06 - val_acc: 1.0000 - val_loss: 2.6878e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8744e-06\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8852e-06 - val_acc: 1.0000 - val_loss: 2.6505e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7721e-06\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7874e-06 - val_acc: 1.0000 - val_loss: 2.6142e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8558e-06\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.8501e-06 - val_acc: 1.0000 - val_loss: 2.5695e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.7852e-06\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.7874e-06 - val_acc: 1.0000 - val_loss: 2.5406e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7662e-06\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7561e-06 - val_acc: 1.0000 - val_loss: 2.4969e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7432e-06\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7373e-06 - val_acc: 1.0000 - val_loss: 2.4606e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6673e-06\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6678e-06 - val_acc: 1.0000 - val_loss: 2.4233e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6852e-06\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6745e-06 - val_acc: 1.0000 - val_loss: 2.3879e-06 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# 모델 학습 및 저장\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.keras', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),  # 확장자 변경\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")\n",
    "# 모델 저장\n",
    "model.save('models/model.keras')  # 확장자 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[94,  0],\n",
       "        [ 0, 34]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 47]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 47]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.keras')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
